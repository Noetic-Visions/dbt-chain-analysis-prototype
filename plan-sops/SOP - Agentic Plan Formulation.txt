**Standard Operating Procedure: AI Agent Plan Formulation and Management**

**Objective:** To establish a rigorous, repeatable process for defining tasks for AI agents, ensuring clarity, manageability, and traceability, thereby mitigating risks associated with the probabilistic nature of AI tools and facilitating the creation of shippable code.

**Scope:** This procedure applies to any task requiring an AI agent to modify or generate code intended for production or integration into a persistent codebase, distinguishing it from mere prototyping or artifact generation ("vibe coding").

**Principle 1: Planning as a Primary Activity**
Effective management necessitates **careful planning**. When utilizing agents for production-oriented tasks, planning constitutes approximately **90% of the overall effort**. This is a deviation from traditional coding workflows and must be acknowledged as a core activity.

**Principle 2: The Plan as a Formal, Versioned Artifact**
The plan is not a transient concept but a **"first-class citizen"** within the project's repository.
*   **Representation:** The plan shall reside in a designated location, such as a `/plans` folder, formatted as a **Markdown file (.md)**.
*   **Content:** The plan must contain not only narrative descriptions but also **real code and data examples** pertinent to the task.
*   **Status:** It functions as **"code as doc,"** providing executable documentation of the intended process.
*   **Requirement:** Plans must be designed for **reusability**, even if the current task is intended for a single execution. The inherent likelihood of the agent's initial execution being incorrect necessitates the ability to re-run the plan after revision.

**Principle 3: Human Expertise as a Precondition**
The successful creation and refinement of plans absolutely demand **significant human expertise**.
*   **Required Skills:** The human operator must possess standard programming skills, **deep architectural insights** relevant to the codebase, and the **ability to communicate clearly and precisely**.
*   **Exclusion:** Individuals lacking these capabilities, such as non-developers, **cannot produce high-quality output** using these tools.
*   **Self-Assessment:** The process requires the developer to confront and acknowledge potential **architectural or implementation problems in their own codebase**. The agent's difficulties in planning often illuminate these "ugly truths".

**Principle 4: Plan Construction Methodology**
Constructing the plan involves articulating the desired sequence of actions in a form understandable by the agent while retaining human control.
*   **Language:** Utilize a **"new programming language"** which is a blend of natural language (e.g., English), pseudocode, and **"arcane references"** to the existing application's files, functions, and data structures.
*   **Input Mechanism:** Employ tools that facilitate direct referencing (e.g., **@mentioning**) code elements to improve plan precision. Include direct examples from existing code within the plan itself.
*   **Modularity:** Deconstruct the overall task into **small, modular parts** or steps. Avoid requesting the agent attempt large or overly complex steps in a single instruction, as this increases the probability of failure and invention of incorrect solutions.
*   **Investigation Phase:** If the feasibility of a particular step or approach is uncertain, the process must revert to an "investigation phase" where the agent assists in refining the plan before execution is attempted.

**Principle 5: Iterative Plan Revision**
It is axiomatic that the plan generated by the agent, even if appearing complete or professional, **will be incorrect upon initial creation**. Revision is a fundamental and mandatory step.
*   **Certainty of Error:** Expect the plan to be **"wrong immediately"**.
*   **Revision Cycle:** Multiple revisions are typically required before the plan is ready for execution.
*   **Revision Strategy:** For simple errors, the human operator may **manually edit the Markdown plan file**. For widespread or complex issues, instruct the agent to revise the entire plan based on specific feedback. Avoid "lecturing the LLM," which adds excessive, confusing context to the prompt chain.

**Principle 6: Plan Testing and Execution Management**
Executing the plan requires deliberate, controlled interaction, distinct from the planning phase.
*   **Separation:** Do not permit the agent to immediately execute the plan upon creation.
*   **Manual Control:** Execute plan steps **one at a time**.
*   **Verification:** After *each* executed step, the human operator must **test and verify the results**. This testing process is crucial and will often reveal underlying technical debt or architectural issues in the human's code. Address revealed code debt through a separate, planned refactoring effort.
*   **Integration:** Save the plan with repository commits. Maintain **clear commit messages** documenting which plans were written, revised, and which specific steps were executed. These "commit breadcrumbs" are vital for rollback and historical analysis.

**Principle 7: Debugging via Re-Planning**
When plan execution or subsequent human testing reveals a problem, the response is not direct correction but a return to the planning methodology.
*   **Procedure:** Do not ask the agent to "fix it" immediately. Instead, request a **plan for the fix**.
*   **Input for Debugging:** Provide detailed input to the agent, such as **screenshots of the problem output**, console/terminal messages, and browser inspector details. Providing architectural diagrams can also be beneficial. This is analogous to writing a detailed issue ticket.

**Principle 8: Strategic Model Selection**
The choice of AI model is consequential and should be aligned with the current phase of the process.
*   **Planning Models:** Utilize models categorized for "Planning/debugging" or "Deep thinking" when creating or significantly revising plans, as these are better equipped for complex reasoning. Be mindful that these models are often more costly.
*   **Action Models:** Once a plan is finalized and being executed step-by-step, switch to "Action models," which are generally cheaper and less prone to inventing or revising instructions during execution. Start a new thread for execution to avoid carrying unnecessary context from the planning phase.
*   **Cost Control:** Regularly monitor model consumption. Disable models that are ineffective or excessively costly. Select the appropriate model for the prompt from available options to control cost and context.

**Principle 9: Leveraging Planning for Refactoring and Improvement**
The planning process inherently aids in identifying areas for code improvement.
*   **Identification:** The agent's difficulty in planning or executing steps often highlights problems in the human's underlying code or architecture.
*   **Application:** Refactoring, informed by issues revealed during planning, is considered an **outstanding use of AI agents**. Develop and execute refactoring tasks using the same rigorous planning methodology. This leads to **"performance payback"** by creating a cleaner, more manageable codebase.

This procedure, grounded in the principles articulated in the sources, provides a structured, if iterative and demanding, pathway for effectively managing AI agents in complex software development environments. It acknowledges the agent's predictive nature and probabilistic output, placing the onus of control, verification, and strategic direction firmly with the human operator.